{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcfOkYKrayjWXd1ek+Rgc8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fToObco9m4IU"},"outputs":[],"source":["# ---  (Regression Version) ---\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import Pipeline  # Added import for Pipeline\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import joblib\n","\n","BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n","DATA_PATH = os.path.join(BASE_DIR, 'Results', 'Output', 'cleaned_student_data.csv')\n","OUT_DIR = os.path.join(BASE_DIR, 'Results', 'Output', 'ModelResults')\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# Load data\n","data = pd.read_csv(\"/content/cleaned_student_data.csv\")\n","\n","# Split features and target\n","TARGET = 'G3'\n","X = data.drop(columns=[TARGET])\n","y = data[TARGET]\n","\n","# Train/test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","\n","# Create a pipeline with PolynomialFeatures, StandardScaler, and LinearRegression\n","pipeline = Pipeline([\n","    ('poly', PolynomialFeatures()),\n","    ('scaler', StandardScaler()),\n","    ('model', LinearRegression())\n","])\n","\n","# Define hyperparameter grid for tuning\n","param_grid = {\n","    'poly__degree': [1, 2, 3],  # Try polynomial degrees 1 (linear), 2, and 3\n","    'model__fit_intercept': [True, False]  # Whether to fit intercept\n","}\n","\n","# Perform GridSearchCV\n","grid_search = GridSearchCV(\n","    pipeline,\n","    param_grid,\n","    cv=5,  # 5-fold cross-validation\n","    scoring='neg_mean_squared_error',\n","    n_jobs=-1\n",")\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best model\n","best_model = grid_search.best_estimator_\n","y_pred = best_model.predict(X_test)\n","\n","# Calculate metrics\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, y_pred)\n","\n","# Print results\n","print(f\"Best Parameters: {grid_search.best_params_}\")\n","print(f\"MAE: {mae:.3f}\")\n","print(f\"MSE: {mse:.3f}\")\n","print(f\"RMSE: {rmse:.3f}\")\n","print(f\"R²: {r2:.3f}\")\n","\n","# Save results\n","results = pd.DataFrame([{\n","    'Model': 'LinearRegression_Tuned',\n","    'MAE': mae,\n","    'MSE': mse,\n","    'RMSE': rmse,\n","    'R2': r2,\n","    'Best_Parameters': str(grid_search.best_params_)\n","}])\n","results.to_csv(os.path.join(OUT_DIR, 'linear_tuned_results.csv'), index=False)\n","\n","# Save the best model\n","joblib.dump(best_model, os.path.join(OUT_DIR, 'linear_tuned_best.joblib'))\n","\n","# Output the saved model path\n","print(f\"Model saved to: {os.path.join(OUT_DIR, 'linear_tuned_best.joblib')}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9vr57SdnZZH","executionInfo":{"status":"ok","timestamp":1761202369282,"user_tz":-330,"elapsed":4123,"user":{"displayName":"savi ambegoda","userId":"11695685256284382480"}},"outputId":"73518d69-b101-43d7-87e5-b0c9d02ff088"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters: {'model__fit_intercept': True, 'poly__degree': 1}\n","MAE: 4.108\n","MSE: 25.813\n","RMSE: 5.081\n","R²: 0.049\n","Model saved to: /Results/Output/ModelResults/linear_tuned_best.joblib\n"]}]}]}